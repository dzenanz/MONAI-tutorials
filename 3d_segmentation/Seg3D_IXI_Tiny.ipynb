{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IXI brain 3D segmentation with MONAI\n",
    "\n",
    "This tutorial shows how to integrate MONAI into an existing PyTorch medical DL program.\n",
    "\n",
    "And easily use below features:\n",
    "1. Transforms for dictionary format data.\n",
    "1. Load Nifti image with metadata.\n",
    "1. Add channel dim to the data if no channel dimension.\n",
    "1. Scale medical image intensity with expected range.\n",
    "1. Crop out a batch of balanced images based on positive / negative label ratio.\n",
    "1. Cache IO and transforms to accelerate training and validation.\n",
    "1. 3D UNet model, Dice loss function, Mean Dice metric for 3D segmentation task.\n",
    "1. Sliding window inference method.\n",
    "1. Deterministic training for reproducibility.\n",
    "\n",
    "The [IXI](https://brain-development.org/ixi-dataset/) Tiny dataset can be downloaded from https://www.dropbox.com/s/ogxjwjxdv5mieah/ixi_tiny.zip?dl=1.\n",
    "\n",
    "Target: Brain  \n",
    "Modality: MRI  \n",
    "Size: 500+ 3D volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"monai[gdown, nibabel]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.2.0\n",
      "Python version: 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]\n",
      "Numpy version: 1.19.1\n",
      "Pytorch version: 1.4.0+cpu\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 7.2.0\n",
      "Tensorboard version: 2.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\MONAI\\Data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "Downloads and extracts the dataset.  \n",
    "The dataset comes from https://torchio.readthedocs.io/_modules/torchio/datasets/ixi.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resource = \"https://www.dropbox.com/s/ogxjwjxdv5mieah/ixi_tiny.zip?dl=1\"\n",
    "md5 = \"BFB60F4074283D78622760230BFA1F98\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"ixi_tiny.zip\")\n",
    "data_dir = os.path.join(root_dir, \"ixi_tiny\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"image\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"label\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation\n",
    "\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. `LoadNiftid` loads the images and labels from NIfTI format files.\n",
    "1. `AddChanneld` as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "1. `Spacingd` adjusts the spacing by `pixdim=(1.5, 1.5, 2.)` based on the affine matrix.\n",
    "1. `Orientationd` unifies the data orientation based on the affine matrix.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "1. `RandAffined` efficiently performs `rotate`, `scale`, `shear`, `translate`, etc. together based on PyTorch affine transform.\n",
    "1. `ToTensord` converts the numpy array to PyTorch Tensor for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(2.18, 4.13, 3.95), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1000, b_min=0.0, b_max=1.0, clip=False,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(32, 32, 32),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        # user can also add other random transforms\n",
    "        # RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=1.0, spatial_size=(96, 96, 96),\n",
    "        #             rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(2.18, 4.13, 3.95), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0, a_max=1000, b_min=0.0, b_max=1.0, clip=False,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([44, 55, 83]), label shape: torch.Size([44, 55, 83])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 80], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 80])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 Load and cache transformed data:  [==============================]\n",
      "9/9 Load and cache transformed data:  [==============================]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=0)\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "model_path = os.path.join(root_dir, \"best_metric_model_ixi_tiny.pth\")\n",
    "if (os.path.exists(model_path)):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded model from file '{model_path}'\")\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n",
      "1/278, train_loss: 0.0738\n",
      "2/278, train_loss: 0.0756\n",
      "3/278, train_loss: 0.0851\n",
      "4/278, train_loss: 0.0713\n",
      "5/278, train_loss: 0.0859\n",
      "6/278, train_loss: 0.0687\n",
      "7/278, train_loss: 0.0662\n",
      "8/278, train_loss: 0.1088\n",
      "9/278, train_loss: 0.0979\n",
      "10/278, train_loss: 0.0759\n",
      "11/278, train_loss: 0.0887\n",
      "12/278, train_loss: 0.0716\n",
      "13/278, train_loss: 0.0630\n",
      "14/278, train_loss: 0.0670\n",
      "15/278, train_loss: 0.0865\n",
      "16/278, train_loss: 0.0697\n",
      "17/278, train_loss: 0.0691\n",
      "18/278, train_loss: 0.0647\n",
      "19/278, train_loss: 0.0653\n",
      "20/278, train_loss: 0.0718\n",
      "21/278, train_loss: 0.0781\n",
      "22/278, train_loss: 0.0814\n",
      "23/278, train_loss: 0.0633\n",
      "24/278, train_loss: 0.0598\n",
      "25/278, train_loss: 0.0862\n",
      "26/278, train_loss: 0.0720\n",
      "27/278, train_loss: 0.0906\n",
      "28/278, train_loss: 0.1352\n",
      "29/278, train_loss: 0.0642\n",
      "30/278, train_loss: 0.1060\n",
      "31/278, train_loss: 0.0639\n",
      "32/278, train_loss: 0.0723\n",
      "33/278, train_loss: 0.0687\n",
      "34/278, train_loss: 0.0680\n",
      "35/278, train_loss: 0.0631\n",
      "36/278, train_loss: 0.0648\n",
      "37/278, train_loss: 0.0693\n",
      "38/278, train_loss: 0.0710\n",
      "39/278, train_loss: 0.0601\n",
      "40/278, train_loss: 0.0793\n",
      "41/278, train_loss: 0.0883\n",
      "42/278, train_loss: 0.1011\n",
      "43/278, train_loss: 0.0597\n",
      "44/278, train_loss: 0.0708\n",
      "45/278, train_loss: 0.0786\n",
      "46/278, train_loss: 0.0630\n",
      "47/278, train_loss: 0.0875\n",
      "48/278, train_loss: 0.0672\n",
      "49/278, train_loss: 0.0818\n",
      "50/278, train_loss: 0.0934\n",
      "51/278, train_loss: 0.0755\n",
      "52/278, train_loss: 0.1169\n",
      "53/278, train_loss: 0.0682\n",
      "54/278, train_loss: 0.1144\n",
      "55/278, train_loss: 0.0610\n",
      "56/278, train_loss: 0.0644\n",
      "57/278, train_loss: 0.0791\n",
      "58/278, train_loss: 0.0694\n",
      "59/278, train_loss: 0.0879\n",
      "60/278, train_loss: 0.0812\n",
      "61/278, train_loss: 0.0620\n",
      "62/278, train_loss: 0.0655\n",
      "63/278, train_loss: 0.0618\n",
      "64/278, train_loss: 0.0675\n",
      "65/278, train_loss: 0.0711\n",
      "66/278, train_loss: 0.0744\n",
      "67/278, train_loss: 0.0771\n",
      "68/278, train_loss: 0.0591\n",
      "69/278, train_loss: 0.0691\n",
      "70/278, train_loss: 0.0826\n",
      "71/278, train_loss: 0.0834\n",
      "72/278, train_loss: 0.0626\n",
      "73/278, train_loss: 0.0644\n",
      "74/278, train_loss: 0.0532\n",
      "75/278, train_loss: 0.0645\n",
      "76/278, train_loss: 0.0646\n",
      "77/278, train_loss: 0.0619\n",
      "78/278, train_loss: 0.0733\n",
      "79/278, train_loss: 0.0790\n",
      "80/278, train_loss: 0.0649\n",
      "81/278, train_loss: 0.0596\n",
      "82/278, train_loss: 0.0589\n",
      "83/278, train_loss: 0.0687\n",
      "84/278, train_loss: 0.0627\n",
      "85/278, train_loss: 0.1033\n",
      "86/278, train_loss: 0.0541\n",
      "87/278, train_loss: 0.0559\n",
      "88/278, train_loss: 0.0950\n",
      "89/278, train_loss: 0.0854\n",
      "90/278, train_loss: 0.0549\n",
      "91/278, train_loss: 0.0611\n",
      "92/278, train_loss: 0.0670\n",
      "93/278, train_loss: 0.0690\n",
      "94/278, train_loss: 0.0575\n",
      "95/278, train_loss: 0.0620\n",
      "96/278, train_loss: 0.0576\n",
      "97/278, train_loss: 0.0750\n",
      "98/278, train_loss: 0.1116\n",
      "99/278, train_loss: 0.0892\n",
      "100/278, train_loss: 0.0655\n",
      "101/278, train_loss: 0.0620\n",
      "102/278, train_loss: 0.0869\n",
      "103/278, train_loss: 0.0624\n",
      "104/278, train_loss: 0.0545\n",
      "105/278, train_loss: 0.1093\n",
      "106/278, train_loss: 0.0645\n",
      "107/278, train_loss: 0.0660\n",
      "108/278, train_loss: 0.0714\n",
      "109/278, train_loss: 0.0619\n",
      "110/278, train_loss: 0.0580\n",
      "111/278, train_loss: 0.0652\n",
      "112/278, train_loss: 0.0711\n",
      "113/278, train_loss: 0.0687\n",
      "114/278, train_loss: 0.0591\n",
      "115/278, train_loss: 0.0545\n",
      "116/278, train_loss: 0.0616\n",
      "117/278, train_loss: 0.0756\n",
      "118/278, train_loss: 0.0601\n",
      "119/278, train_loss: 0.0670\n",
      "120/278, train_loss: 0.0592\n",
      "121/278, train_loss: 0.0523\n",
      "122/278, train_loss: 0.0658\n",
      "123/278, train_loss: 0.0733\n",
      "124/278, train_loss: 0.0665\n",
      "125/278, train_loss: 0.0643\n",
      "126/278, train_loss: 0.0593\n",
      "127/278, train_loss: 0.0573\n",
      "128/278, train_loss: 0.0591\n",
      "129/278, train_loss: 0.0598\n",
      "130/278, train_loss: 0.0533\n",
      "131/278, train_loss: 0.0566\n",
      "132/278, train_loss: 0.0554\n",
      "133/278, train_loss: 0.0609\n",
      "134/278, train_loss: 0.0537\n",
      "135/278, train_loss: 0.0618\n",
      "136/278, train_loss: 0.0574\n",
      "137/278, train_loss: 0.0718\n",
      "138/278, train_loss: 0.0833\n",
      "139/278, train_loss: 0.0775\n",
      "140/278, train_loss: 0.0811\n",
      "141/278, train_loss: 0.0810\n",
      "142/278, train_loss: 0.0933\n",
      "143/278, train_loss: 0.0881\n",
      "144/278, train_loss: 0.0745\n",
      "145/278, train_loss: 0.0605\n",
      "146/278, train_loss: 0.0694\n",
      "147/278, train_loss: 0.0513\n",
      "148/278, train_loss: 0.0836\n",
      "149/278, train_loss: 0.0639\n",
      "150/278, train_loss: 0.0947\n",
      "151/278, train_loss: 0.0726\n",
      "152/278, train_loss: 0.0633\n",
      "153/278, train_loss: 0.0685\n",
      "154/278, train_loss: 0.0757\n",
      "155/278, train_loss: 0.0534\n",
      "156/278, train_loss: 0.0565\n",
      "157/278, train_loss: 0.0714\n",
      "158/278, train_loss: 0.0549\n",
      "159/278, train_loss: 0.0570\n",
      "160/278, train_loss: 0.0544\n",
      "161/278, train_loss: 0.0503\n",
      "162/278, train_loss: 0.0591\n",
      "163/278, train_loss: 0.0638\n",
      "164/278, train_loss: 0.0574\n",
      "165/278, train_loss: 0.0627\n",
      "166/278, train_loss: 0.0637\n",
      "167/278, train_loss: 0.1001\n",
      "168/278, train_loss: 0.0876\n",
      "169/278, train_loss: 0.0702\n",
      "170/278, train_loss: 0.0677\n",
      "171/278, train_loss: 0.0814\n",
      "172/278, train_loss: 0.0525\n",
      "173/278, train_loss: 0.0536\n",
      "174/278, train_loss: 0.0524\n",
      "175/278, train_loss: 0.0818\n",
      "176/278, train_loss: 0.0913\n",
      "177/278, train_loss: 0.0961\n",
      "178/278, train_loss: 0.0596\n",
      "179/278, train_loss: 0.0537\n",
      "180/278, train_loss: 0.0854\n",
      "181/278, train_loss: 0.0767\n",
      "182/278, train_loss: 0.0571\n",
      "183/278, train_loss: 0.0569\n",
      "184/278, train_loss: 0.0521\n",
      "185/278, train_loss: 0.0547\n",
      "186/278, train_loss: 0.0771\n",
      "187/278, train_loss: 0.0513\n",
      "188/278, train_loss: 0.0714\n",
      "189/278, train_loss: 0.0573\n",
      "190/278, train_loss: 0.0577\n",
      "191/278, train_loss: 0.0640\n",
      "192/278, train_loss: 0.0545\n",
      "193/278, train_loss: 0.0660\n",
      "194/278, train_loss: 0.0592\n",
      "195/278, train_loss: 0.0928\n",
      "196/278, train_loss: 0.0508\n",
      "197/278, train_loss: 0.0727\n",
      "198/278, train_loss: 0.0576\n",
      "199/278, train_loss: 0.0570\n",
      "200/278, train_loss: 0.0700\n",
      "201/278, train_loss: 0.0645\n",
      "202/278, train_loss: 0.0517\n",
      "203/278, train_loss: 0.0599\n",
      "204/278, train_loss: 0.0678\n",
      "205/278, train_loss: 0.0759\n",
      "206/278, train_loss: 0.0892\n",
      "207/278, train_loss: 0.0743\n",
      "208/278, train_loss: 0.0524\n",
      "209/278, train_loss: 0.0622\n",
      "210/278, train_loss: 0.0631\n",
      "211/278, train_loss: 0.0886\n",
      "212/278, train_loss: 0.1174\n",
      "213/278, train_loss: 0.0626\n",
      "214/278, train_loss: 0.0524\n",
      "215/278, train_loss: 0.0640\n",
      "216/278, train_loss: 0.0534\n",
      "217/278, train_loss: 0.0638\n",
      "218/278, train_loss: 0.0775\n",
      "219/278, train_loss: 0.0619\n",
      "220/278, train_loss: 0.0525\n",
      "221/278, train_loss: 0.0576\n",
      "222/278, train_loss: 0.0550\n",
      "223/278, train_loss: 0.0548\n",
      "224/278, train_loss: 0.0576\n",
      "225/278, train_loss: 0.0490\n",
      "226/278, train_loss: 0.0605\n",
      "227/278, train_loss: 0.0688\n",
      "228/278, train_loss: 0.0853\n",
      "229/278, train_loss: 0.0587\n",
      "230/278, train_loss: 0.0720\n",
      "231/278, train_loss: 0.0554\n",
      "232/278, train_loss: 0.0545\n",
      "233/278, train_loss: 0.0553\n",
      "234/278, train_loss: 0.0569\n",
      "235/278, train_loss: 0.0528\n",
      "236/278, train_loss: 0.0705\n",
      "237/278, train_loss: 0.0588\n",
      "238/278, train_loss: 0.0663\n",
      "239/278, train_loss: 0.0619\n",
      "240/278, train_loss: 0.0635\n",
      "241/278, train_loss: 0.0521\n",
      "242/278, train_loss: 0.0870\n",
      "243/278, train_loss: 0.0664\n",
      "244/278, train_loss: 0.0551\n",
      "245/278, train_loss: 0.0702\n",
      "246/278, train_loss: 0.0701\n",
      "247/278, train_loss: 0.0638\n",
      "248/278, train_loss: 0.0665\n",
      "249/278, train_loss: 0.0687\n",
      "250/278, train_loss: 0.0751\n",
      "251/278, train_loss: 0.0483\n",
      "252/278, train_loss: 0.0714\n",
      "253/278, train_loss: 0.0453\n",
      "254/278, train_loss: 0.0781\n",
      "255/278, train_loss: 0.0603\n",
      "256/278, train_loss: 0.0825\n",
      "257/278, train_loss: 0.0535\n",
      "258/278, train_loss: 0.0545\n",
      "259/278, train_loss: 0.0585\n",
      "260/278, train_loss: 0.0544\n",
      "261/278, train_loss: 0.0654\n",
      "262/278, train_loss: 0.0550\n",
      "263/278, train_loss: 0.0679\n",
      "264/278, train_loss: 0.0607\n",
      "265/278, train_loss: 0.0734\n",
      "266/278, train_loss: 0.0517\n",
      "267/278, train_loss: 0.0682\n",
      "268/278, train_loss: 0.0508\n",
      "269/278, train_loss: 0.0492\n",
      "270/278, train_loss: 0.0599\n",
      "271/278, train_loss: 0.0740\n",
      "272/278, train_loss: 0.0520\n",
      "273/278, train_loss: 0.0696\n",
      "274/278, train_loss: 0.0448\n",
      "275/278, train_loss: 0.0568\n",
      "276/278, train_loss: 0.0520\n",
      "277/278, train_loss: 0.1024\n",
      "278/278, train_loss: 0.0884\n",
      "279/278, train_loss: 0.0508\n",
      "epoch 1 average loss: 0.0685\n",
      "----------\n",
      "epoch 2/10\n",
      "1/278, train_loss: 0.0644\n",
      "2/278, train_loss: 0.0505\n",
      "3/278, train_loss: 0.0563\n",
      "4/278, train_loss: 0.0563\n",
      "5/278, train_loss: 0.0745\n",
      "6/278, train_loss: 0.0567\n",
      "7/278, train_loss: 0.0523\n",
      "8/278, train_loss: 0.0483\n",
      "9/278, train_loss: 0.0611\n",
      "10/278, train_loss: 0.0481\n",
      "11/278, train_loss: 0.0649\n",
      "12/278, train_loss: 0.0502\n",
      "13/278, train_loss: 0.0481\n",
      "14/278, train_loss: 0.0664\n",
      "15/278, train_loss: 0.0470\n",
      "16/278, train_loss: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/278, train_loss: 0.0723\n",
      "18/278, train_loss: 0.0592\n",
      "19/278, train_loss: 0.0494\n",
      "20/278, train_loss: 0.0562\n",
      "21/278, train_loss: 0.0653\n",
      "22/278, train_loss: 0.0726\n",
      "23/278, train_loss: 0.0601\n",
      "24/278, train_loss: 0.0477\n",
      "25/278, train_loss: 0.0644\n",
      "26/278, train_loss: 0.0513\n",
      "27/278, train_loss: 0.0655\n",
      "28/278, train_loss: 0.0599\n",
      "29/278, train_loss: 0.0499\n",
      "30/278, train_loss: 0.0666\n",
      "31/278, train_loss: 0.0538\n",
      "32/278, train_loss: 0.0833\n",
      "33/278, train_loss: 0.0569\n",
      "34/278, train_loss: 0.0537\n",
      "35/278, train_loss: 0.0538\n",
      "36/278, train_loss: 0.0531\n",
      "37/278, train_loss: 0.0445\n",
      "38/278, train_loss: 0.0484\n",
      "39/278, train_loss: 0.0583\n",
      "40/278, train_loss: 0.0472\n",
      "41/278, train_loss: 0.0629\n",
      "42/278, train_loss: 0.0471\n",
      "43/278, train_loss: 0.0565\n",
      "44/278, train_loss: 0.0499\n",
      "45/278, train_loss: 0.0752\n",
      "46/278, train_loss: 0.0593\n",
      "47/278, train_loss: 0.0535\n",
      "48/278, train_loss: 0.0469\n",
      "49/278, train_loss: 0.0515\n",
      "50/278, train_loss: 0.0452\n",
      "51/278, train_loss: 0.0513\n",
      "52/278, train_loss: 0.0494\n",
      "53/278, train_loss: 0.0900\n",
      "54/278, train_loss: 0.0903\n",
      "55/278, train_loss: 0.0657\n",
      "56/278, train_loss: 0.0678\n",
      "57/278, train_loss: 0.0440\n",
      "58/278, train_loss: 0.0687\n",
      "59/278, train_loss: 0.0679\n",
      "60/278, train_loss: 0.0704\n",
      "61/278, train_loss: 0.0597\n",
      "62/278, train_loss: 0.0452\n",
      "63/278, train_loss: 0.0541\n",
      "64/278, train_loss: 0.0614\n",
      "65/278, train_loss: 0.0452\n",
      "66/278, train_loss: 0.0576\n",
      "67/278, train_loss: 0.0821\n",
      "68/278, train_loss: 0.0561\n",
      "69/278, train_loss: 0.0622\n",
      "70/278, train_loss: 0.0609\n",
      "71/278, train_loss: 0.0552\n",
      "72/278, train_loss: 0.0668\n",
      "73/278, train_loss: 0.0454\n",
      "74/278, train_loss: 0.0610\n",
      "75/278, train_loss: 0.0459\n",
      "76/278, train_loss: 0.0422\n",
      "77/278, train_loss: 0.0488\n",
      "78/278, train_loss: 0.0481\n",
      "79/278, train_loss: 0.0523\n",
      "80/278, train_loss: 0.0502\n",
      "81/278, train_loss: 0.0501\n",
      "82/278, train_loss: 0.0531\n",
      "83/278, train_loss: 0.0555\n",
      "84/278, train_loss: 0.0449\n",
      "85/278, train_loss: 0.0508\n",
      "86/278, train_loss: 0.0598\n",
      "87/278, train_loss: 0.0674\n",
      "88/278, train_loss: 0.0558\n",
      "89/278, train_loss: 0.0575\n",
      "90/278, train_loss: 0.0510\n",
      "91/278, train_loss: 0.0612\n",
      "92/278, train_loss: 0.0673\n",
      "93/278, train_loss: 0.0707\n",
      "94/278, train_loss: 0.0529\n",
      "95/278, train_loss: 0.0506\n",
      "96/278, train_loss: 0.0771\n",
      "97/278, train_loss: 0.0484\n",
      "98/278, train_loss: 0.0445\n",
      "99/278, train_loss: 0.0489\n",
      "100/278, train_loss: 0.0492\n",
      "101/278, train_loss: 0.0561\n",
      "102/278, train_loss: 0.0470\n",
      "103/278, train_loss: 0.0585\n",
      "104/278, train_loss: 0.0458\n",
      "105/278, train_loss: 0.0545\n",
      "106/278, train_loss: 0.0434\n",
      "107/278, train_loss: 0.0972\n",
      "108/278, train_loss: 0.0451\n",
      "109/278, train_loss: 0.0605\n",
      "110/278, train_loss: 0.0667\n",
      "111/278, train_loss: 0.0464\n",
      "112/278, train_loss: 0.0438\n",
      "113/278, train_loss: 0.0579\n",
      "114/278, train_loss: 0.0486\n",
      "115/278, train_loss: 0.0539\n",
      "116/278, train_loss: 0.0735\n",
      "117/278, train_loss: 0.0532\n",
      "118/278, train_loss: 0.0480\n",
      "119/278, train_loss: 0.0646\n",
      "120/278, train_loss: 0.0449\n",
      "121/278, train_loss: 0.0459\n",
      "122/278, train_loss: 0.0458\n",
      "123/278, train_loss: 0.0557\n",
      "124/278, train_loss: 0.0536\n",
      "125/278, train_loss: 0.0429\n",
      "126/278, train_loss: 0.0483\n",
      "127/278, train_loss: 0.0658\n",
      "128/278, train_loss: 0.0514\n",
      "129/278, train_loss: 0.0411\n",
      "130/278, train_loss: 0.0665\n",
      "131/278, train_loss: 0.0497\n",
      "132/278, train_loss: 0.0617\n",
      "133/278, train_loss: 0.0583\n",
      "134/278, train_loss: 0.0462\n",
      "135/278, train_loss: 0.0528\n",
      "136/278, train_loss: 0.0942\n",
      "137/278, train_loss: 0.0608\n",
      "138/278, train_loss: 0.0475\n",
      "139/278, train_loss: 0.0682\n",
      "140/278, train_loss: 0.0525\n",
      "141/278, train_loss: 0.0404\n",
      "142/278, train_loss: 0.0572\n",
      "143/278, train_loss: 0.0441\n",
      "144/278, train_loss: 0.0495\n",
      "145/278, train_loss: 0.0579\n",
      "146/278, train_loss: 0.0454\n",
      "147/278, train_loss: 0.0490\n",
      "148/278, train_loss: 0.0703\n",
      "149/278, train_loss: 0.0491\n",
      "150/278, train_loss: 0.0418\n",
      "151/278, train_loss: 0.0747\n",
      "152/278, train_loss: 0.0535\n",
      "153/278, train_loss: 0.0522\n",
      "154/278, train_loss: 0.0572\n",
      "155/278, train_loss: 0.0543\n",
      "156/278, train_loss: 0.0536\n",
      "157/278, train_loss: 0.0495\n",
      "158/278, train_loss: 0.0456\n",
      "159/278, train_loss: 0.0555\n",
      "160/278, train_loss: 0.0465\n",
      "161/278, train_loss: 0.0473\n",
      "162/278, train_loss: 0.0459\n",
      "163/278, train_loss: 0.0630\n",
      "164/278, train_loss: 0.0426\n",
      "165/278, train_loss: 0.0465\n",
      "166/278, train_loss: 0.0620\n",
      "167/278, train_loss: 0.0632\n",
      "168/278, train_loss: 0.0621\n",
      "169/278, train_loss: 0.0463\n",
      "170/278, train_loss: 0.0459\n",
      "171/278, train_loss: 0.0524\n",
      "172/278, train_loss: 0.0520\n",
      "173/278, train_loss: 0.0460\n",
      "174/278, train_loss: 0.0630\n",
      "175/278, train_loss: 0.0482\n",
      "176/278, train_loss: 0.0556\n",
      "177/278, train_loss: 0.0558\n",
      "178/278, train_loss: 0.0497\n",
      "179/278, train_loss: 0.0610\n",
      "180/278, train_loss: 0.0749\n",
      "181/278, train_loss: 0.0494\n",
      "182/278, train_loss: 0.0398\n",
      "183/278, train_loss: 0.0496\n",
      "184/278, train_loss: 0.0462\n",
      "185/278, train_loss: 0.0504\n",
      "186/278, train_loss: 0.0539\n",
      "187/278, train_loss: 0.0597\n",
      "188/278, train_loss: 0.0627\n",
      "189/278, train_loss: 0.0427\n",
      "190/278, train_loss: 0.0463\n",
      "191/278, train_loss: 0.0418\n",
      "192/278, train_loss: 0.0494\n",
      "193/278, train_loss: 0.0473\n",
      "194/278, train_loss: 0.0481\n",
      "195/278, train_loss: 0.0544\n",
      "196/278, train_loss: 0.0425\n",
      "197/278, train_loss: 0.0446\n",
      "198/278, train_loss: 0.0407\n",
      "199/278, train_loss: 0.0602\n",
      "200/278, train_loss: 0.0532\n",
      "201/278, train_loss: 0.0608\n",
      "202/278, train_loss: 0.0702\n",
      "203/278, train_loss: 0.0503\n",
      "204/278, train_loss: 0.0430\n",
      "205/278, train_loss: 0.0533\n",
      "206/278, train_loss: 0.0731\n",
      "207/278, train_loss: 0.0644\n",
      "208/278, train_loss: 0.0545\n",
      "209/278, train_loss: 0.0498\n",
      "210/278, train_loss: 0.0412\n",
      "211/278, train_loss: 0.0622\n",
      "212/278, train_loss: 0.0444\n",
      "213/278, train_loss: 0.0449\n",
      "214/278, train_loss: 0.0437\n",
      "215/278, train_loss: 0.0548\n",
      "216/278, train_loss: 0.0424\n",
      "217/278, train_loss: 0.0582\n",
      "218/278, train_loss: 0.0478\n",
      "219/278, train_loss: 0.0557\n",
      "220/278, train_loss: 0.0560\n",
      "221/278, train_loss: 0.0691\n",
      "222/278, train_loss: 0.0662\n",
      "223/278, train_loss: 0.0494\n",
      "224/278, train_loss: 0.0523\n",
      "225/278, train_loss: 0.0482\n",
      "226/278, train_loss: 0.0490\n",
      "227/278, train_loss: 0.0432\n",
      "228/278, train_loss: 0.0502\n",
      "229/278, train_loss: 0.0773\n",
      "230/278, train_loss: 0.0364\n",
      "231/278, train_loss: 0.0514\n",
      "232/278, train_loss: 0.0576\n",
      "233/278, train_loss: 0.0514\n",
      "234/278, train_loss: 0.0376\n",
      "235/278, train_loss: 0.0572\n",
      "236/278, train_loss: 0.0493\n",
      "237/278, train_loss: 0.0391\n",
      "238/278, train_loss: 0.0553\n",
      "239/278, train_loss: 0.0533\n",
      "240/278, train_loss: 0.0571\n",
      "241/278, train_loss: 0.0497\n",
      "242/278, train_loss: 0.0473\n",
      "243/278, train_loss: 0.0455\n",
      "244/278, train_loss: 0.0744\n",
      "245/278, train_loss: 0.0601\n",
      "246/278, train_loss: 0.0495\n",
      "247/278, train_loss: 0.0410\n",
      "248/278, train_loss: 0.0460\n",
      "249/278, train_loss: 0.0449\n",
      "250/278, train_loss: 0.0577\n",
      "251/278, train_loss: 0.0480\n",
      "252/278, train_loss: 0.0508\n",
      "253/278, train_loss: 0.0423\n",
      "254/278, train_loss: 0.0468\n",
      "255/278, train_loss: 0.0460\n",
      "256/278, train_loss: 0.0479\n",
      "257/278, train_loss: 0.0399\n",
      "258/278, train_loss: 0.0448\n",
      "259/278, train_loss: 0.0426\n",
      "260/278, train_loss: 0.0367\n",
      "261/278, train_loss: 0.0423\n",
      "262/278, train_loss: 0.0459\n",
      "263/278, train_loss: 0.0474\n",
      "264/278, train_loss: 0.0549\n",
      "265/278, train_loss: 0.0670\n",
      "266/278, train_loss: 0.0427\n",
      "267/278, train_loss: 0.0460\n",
      "268/278, train_loss: 0.0562\n",
      "269/278, train_loss: 0.0626\n",
      "270/278, train_loss: 0.0420\n",
      "271/278, train_loss: 0.0577\n",
      "272/278, train_loss: 0.0435\n",
      "273/278, train_loss: 0.0408\n",
      "274/278, train_loss: 0.0473\n",
      "275/278, train_loss: 0.0487\n",
      "276/278, train_loss: 0.0498\n",
      "277/278, train_loss: 0.0444\n",
      "278/278, train_loss: 0.0395\n",
      "279/278, train_loss: 0.0655\n",
      "epoch 2 average loss: 0.0541\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 7 and 8 in dimension 3 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-73b68b1d136e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mroi_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0msw_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mval_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msliding_window_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msw_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 value = compute_meandice(\n\u001b[0;32m     45\u001b[0m                     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\inferers\\utils.py\u001b[0m in \u001b[0;36msliding_window_inference\u001b[1;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, padding_mode, cval)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0moutput_rois\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslice_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mseg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# batched patch segmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[0moutput_rois\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\nets\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 7 and 8 in dimension 3 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (-1, -1, -1)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                value = compute_meandice(\n",
    "                    y_pred=val_outputs,\n",
    "                    y=val_labels,\n",
    "                    include_background=False,\n",
    "                    to_onehot_y=True,\n",
    "                    mutually_exclusive=True,\n",
    "                )\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f}  at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        roi_size = (-1, -1, -1)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "        )\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
