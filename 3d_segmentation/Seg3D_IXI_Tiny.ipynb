{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IXI brain 3D segmentation with MONAI\n",
    "\n",
    "This tutorial shows how to integrate MONAI into an existing PyTorch medical DL program.\n",
    "\n",
    "And easily use below features:\n",
    "1. Transforms for dictionary format data.\n",
    "1. Load Nifti image with metadata.\n",
    "1. Add channel dim to the data if no channel dimension.\n",
    "1. Scale medical image intensity with expected range.\n",
    "1. Crop out a batch of balanced images based on positive / negative label ratio.\n",
    "1. Cache IO and transforms to accelerate training and validation.\n",
    "1. 3D UNet model, Dice loss function, Mean Dice metric for 3D segmentation task.\n",
    "1. Sliding window inference method.\n",
    "1. Deterministic training for reproducibility.\n",
    "\n",
    "The [IXI](https://brain-development.org/ixi-dataset/) Tiny dataset can be downloaded from https://www.dropbox.com/s/ogxjwjxdv5mieah/ixi_tiny.zip?dl=1.\n",
    "\n",
    "Target: Brain  \n",
    "Modality: MRI  \n",
    "Size: 500+ 3D volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"monai[gdown, nibabel]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.2.0\n",
      "Python version: 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]\n",
      "Numpy version: 1.19.1\n",
      "Pytorch version: 1.4.0+cpu\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.3.0\n",
      "Nibabel version: 3.1.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 7.2.0\n",
      "Tensorboard version: 2.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\MONAI\\Data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "Downloads and extracts the dataset.  \n",
    "The dataset comes from https://torchio.readthedocs.io/_modules/torchio/datasets/ixi.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resource = \"https://www.dropbox.com/s/ogxjwjxdv5mieah/ixi_tiny.zip?dl=1\"\n",
    "md5 = \"BFB60F4074283D78622760230BFA1F98\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"ixi_tiny.zip\")\n",
    "data_dir = os.path.join(root_dir, \"ixi_tiny\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"image\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"label\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation\n",
    "\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. `LoadNiftid` loads the images and labels from NIfTI format files.\n",
    "1. `AddChanneld` as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "1. `Spacingd` adjusts the spacing by `pixdim=(1.5, 1.5, 2.)` based on the affine matrix.\n",
    "1. `Orientationd` unifies the data orientation based on the affine matrix.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "1. `CropForegroundd` removes all zero borders to focus on the valid body area of the images and labels.\n",
    "1. `RandCropByPosNegLabeld` randomly crop patch samples from big image based on pos / neg ratio.  \n",
    "The image centers of negative samples must be in valid body area.\n",
    "1. `RandAffined` efficiently performs `rotate`, `scale`, `shear`, `translate`, etc. together based on PyTorch affine transform.\n",
    "1. `ToTensord` converts the numpy array to PyTorch Tensor for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        # user can also add other random transforms\n",
    "        # RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.8, spatial_size=(83, 44, 55),\n",
    "        #             rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([83, 44, 55]), label shape: torch.Size([83, 44, 55])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAF1CAYAAADssDCjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5d0lEQVR4nO3de5Cdd33f8c8XWXdptauLV6uVbAnLF8VXwOOYkKSAIcEkxKSlTC7TcRNnnGnSljRJg0mnnbbTdpxpJoROOkndQOO2CYaQUFOahNrGTMoEMAY7GOOLZNmyLqvr7uqOsM2vf+zR8vw+u3t+5+zl7Nln368Zjc93z+33PGf1+Kfn+ZzvL1JKAgAAqLPXzfcAAAAA5hoTHgAAUHtMeAAAQO0x4QEAALXHhAcAANQeEx4AAFB7THjmWUQ8HRFvne9xAADaFxEvRcQ7Wnhcioid03yPaT8X33PJfA9gsUspXTvfYwAAoO44wwMAAGqPCc88u3g6NCL+dUT8aUT8z4g4HRFPRcRVEfGhiDgaEfsj4kcqz/u5iHim8di9EfGL9rq/ERFDEXEoIn6heko0IpZHxG9HxMsRcSQi/iAiVnZ62wGgLiLiloj4UkSMNo69vxcRy+xh724cr49HxH+MiNdVnv/zjWP6SER8LiIu7/Am1B4Tnu7yHkn/Q1KfpCckfU5jn9GgpH8r6b9UHntU0o9L6pH0c5I+HBFvlKSIeJekX5X0Dkk7Jb3V3udeSVdJuqlx/6CkfzUH2wMAi8Vrkv6ZpI2S3izpNkm/ZI/5SUk3S3qjpDsk/bwkRcQdkn5T0t+VtEnS/5P08Y6MehEJ1tKaXxHxkqRfkPSDkt6SUnpn4+fv0dgv/LqU0msRsVbSKUl9KaXRSV7nf0l6NKX0kYj4mKQjKaUPNe7bKWm3pCslvSDpjKQbUkovNO5/s6Q/SSntmMttBYC6uXgMTyk9bD//FUl/J6X0k406Sbo9pfRXjfqXJP29lNJtEfGXkj6VUvpo477Xaew4vSultK/x3CtTSns6tV11xBme7nKkcvu8pOMppdcqtSStkaSIuD0ivhwRwxExKundGvuXhSRtkbS/8lrV25skrZL0tcap11FJf9X4OQBgGhoRhM9GxOGIOCXpP+h7x+SLqsfifRo7VkvS5ZI+UjkmD0sKjZ19xyxhwrMARcRySX8m6bcl9aeUeiX9hcb+gkjSkKStladsq9w+rrHJ07Uppd7Gn3UppTVzP3IAqK3fl/Ssxs7E9GjsElXYY6rH4sskHWrc3i/pFyvH5N6U0sqU0t/M+agXESY8C9MyScslHZP0akTcLulHKvd/UtLPRcSuiFgl6V9evCOl9F1J/1VjmZ9LJSkiBiPiRzs2egCon4uxgzMRcY2kfzTJY/55RPRFxDZJH5D0icbP/0DShyLiWkmKiHUR8fc7MejFhAnPApRSOi3pn2psYjMi6WckfaZy/19K+k+SHpW0R9KXG3ddaPz3gxd/3jj1+rCkqzsyeACop1/X2LH4tMb+UfmJSR7zoKSvSXpS0v+R9FFJSil9WtJvSXqgcUz+pqTb537Iiwuh5UUgInZp7C/Q8pTSq/M9HgAAOo0zPDUVET/Z6LfTp7F/OfxvJjsAgMWKCU99/aLGevW8oLH+EJNdTwYAYFHgkhYAAKi9GZ3hiYh3RcRzEbEnIu6ZrUEBAGYfx2wsZtM+wxMRSyQ9L+mdkg5I+qqkn04pfWv2hgcAmA0cs7HYXTKD594iaU9Kaa8kRcQDGlsbZMq/PI322FNasmRJVvf29jYdwNKlS7P6u9/9bla/+mrrGd0LFy5k9YoVK5qOzSeKEd5fKnfJJfmu/va3v9309Zcty9ec8207fvz4+O3Sdr7udfmJvM2bNzd9/GuvvZbVPnZ/P98Xpdp95zvfafr45cuXj9/2/eD73bfVX+uVV17J6tOnT2e1b7vGul3ThRp10PYxe1ksTyu0ukPDA2butEamPGbPZMIzqLxN9gFJ39/OC/j/rNatW5fV73nPe5o+v7+/P6vPnz+f1SdOnBi/Xfof4Z49+RIl11xzTVavXbu26fN98uWTgk2b8v3/3HPPZbVP7rZu3ZrVvm0f+9jHxm9XJz/SxP3qk6df/uVfVjOnTp3Kah/7sWPHstonET4p8QmNj2///v1Z7Y/fvn37+G2fKPrn2tPTk9X++MOHD2f1F77whaw+efJkVn/3u9/dJ6Ae2j5mr9BqfX/cNqeDAmbTw+lTUx6zZzLhaUlE3C3p7rl+HwDAzFWP2Su0ap5HA8yemUx4DipfF2Rr42eZlNJ9ku6TJl7S8n/pr1y50p+b1X4WxM8E+GWh6uv5WQs/I1O9bCJNvKTlfGx+RsfPqoyMjGS1nwXxsfvjn3766ayubk/pkpGfgfnSl76U1dddd11W++fiY/HLf36WxbetVPsZqoGBgaz28VedPXs2q9esyZcE8/fyS1Z8SxGLSNvH7J5Yz18Q1MZMvqX1VUlXRsSOiFgm6adUWd4AANBVOGZjUZv2GZ6U0qsR8Y8lfU7SEkkfSyk9XXgaAGAecMzGYjejDE9K6S8k/cUsjQUAMIc4ZmMxm/PQcjOen/Aci+ctPHdz5syZrB4dHc3qwcHB8dv+bR3Pofg3kTzH4lkQz614nshf33MonhE6d+5cVvu2V79xJuWZoVIOxfebv9fw8HBWr1qVBxV92z3vVPqWVml8/n4+3upXx/2xnvtypd8xHysAoJ5YSwsAANQeEx4AAFB7THgAAEDtzWuGx3MypSUJPNeyenXe8tx74VTzHf7cvr6+rPbMjfPMji+34LX3h/Hne58e76TsnZ2b9bopLbfg+3HXrl1Nx+rdij3z49vq+9bfv7RUhS914Xmram8d3xbPQvl+cqWeQQCAeuIMDwAAqD0mPAAAoPaY8AAAgNrrqgxPu1kQ76mycePGrK6uAeVZD++b4/1c/LVLPJfi+SLP7JS2xbMqvhZYOxkefy/n+8af771vfFt9X/r9pVyN7xt/vWqmx/NEW7ZsyWrPcZWyVwCAxYEzPAAAoPaY8AAAgNpjwgMAAGqvq9bS8qxJKdPjeYxt27Zl9cMPPzx+e926dW29livlUEp9eTwn471vPLfi9x8/fjyrq/vOt6WU4Xn66XyB5GuuuSarfW0szyP551bad6W+QD4+3xfeo6iqlP/xsfk6YO2u+wUAWJg4wwMAAGqPCQ8AAKg9JjwAAKD2uqopiecnSv1lvHfNiRMnsvrMmTNTvrb37CmNxTM8fr+PxXMnpW3x13/55Zez2vvLVLMp/lrOx7p3796s3rRpU1Zv3759yveabCyejzp58mRWl8bn+85zOUuXLh2/Xcr/+HNLmZzS2AAA9cAZHgAAUHtMeAAAQO0x4QEAALXXVX14SnkKz8FU11iSpNOnT2d1tfdNNQciTew14/eXeK7FX8/XfPKx79q1K6s9e3Lw4MGs3rp1a1aPjo6O3/YeP/5e3tPHx+4ZnKuuuiqr9+3bl9W+7pjvO/8cPKPj+2p4eDirfd2w6vN7enqaPnbz5s1Z7b8jrtRfCQBQDxztAQBA7THhAQAAtceEBwAA1N68ZnhKmR3vsVLK8HhdzdF49sP5GkyeqfGsRynz42P1vjye8fHxXXvttVl96aWXZnU1w3PhwoXsPs/Y+HuNjIxktfck8n5GnpM5evRoVvu+8NozRNWxT1Z7pqe6fT5Wzx/19vZmteeF/HMp9VcCANQDZ3gAAEDtMeEBAAC111VLS/jlhdLlBr90cujQoayuLi3hl2nWrl2b1b5cwpo1a7J6aGgoq/1ym3/V259/+PDhrH7uueey2i9pXXHFFVntl9iql+982wYGBrJ6w4YNTWvfti9/+ctZvXz58qz2S2b+tXUfq1+y8stS69evz+r9+/dndfWSml+i8q/ADw4OZrVfwvLfGf/KPACgnjjDAwAAao8JDwAAqL3ihCciPhYRRyPim5WfrY+IhyJid+O/fXM7TABAqzhuAxO1kuH5I0m/J+m/V352j6RHUkr3RsQ9jfqDMx1MaQkCz2N4tsSzKEeOHBm/Xc3zSNLq1aub1v7V6GeeeabpWDyz88M//MNNx+ZfU/ev1HteycdTzRD5tvljPR/k+80zNr5UxaZNm5q+nn+l3zM4no/ybfM8lX/NvpoJ8m3zr7yXltHw2rfVWyXwNXUsUH+kDh23gYWieIYnpfTXkobtx3dIur9x+35J753dYQEApovjNjDRdDM8/Smli6csDkvqn6XxAADmBsdtLGoz/lp6SilFxJTn/SPibkl3z/R9AACzo9lxu3rMXqFVHR0XMJemO+E5EhEDKaWhiBiQdHSqB6aU7pN0nyT5XzDPS3gOxvvweO7Fe6p4r5tqnsMzMt5Hx3vHeObGcyWlDJCPrdT7xnvR+HIOnrOpPt6XV/DneqbGMzyewdm5c2dWb9++Pav9c3rb296W1V/60pey+sCBA1nt2+Lj88/99a9//fjtai5rstf234EdO3Zktf8O+ecO1FhLx+3qMbsn1hNiq4HPHXqy6f0/uuWmjoxjvk33ktZnJN3ZuH2npAdnZzgAgDnCcRuLWitfS/+4pC9JujoiDkTEXZLulfTOiNgt6R2NGgDQBThuAxMVL2mllH56irtum+WxAABmAcdtYKKuWkvLsyXOMz8vvPBCVnu/l2quxvuzeE7E14PyNZquvPLKrPZcS29vb1Z7b5nrr78+q0+ePJnVnrvx/i/++sePHx+/7dviuZRz5841HZv3FPK1uDwjVMpa/cAP/EBW7969O6s9T+X3e2+cbdu2jd/u78+/WFLdD9LEz83X/fLfg9LvHICFqZRbKVnIuZZ2t73dxy/UfcPSEgAAoPaY8AAAgNpjwgMAAGpvQWV4PIvieY3NmzdndTXv8dWvfjW778SJE1nt+Z8tW7Zk9U033ZTVfX35unveh8dzKr5tV1xxRVZ7fxnvy3Po0KGsrmaAPENTem3P+Hg+qJTR8VyMZ4C855DzXjgHDx7Mas/ZVNdY8/3u2Sr/HLx/kueDvF8SgIVpppmd0ut1c25ltre9rjjDAwAAao8JDwAAqD0mPAAAoPY6nuHxXjpVni3x+pVXXsnqUnal+nzva+O5E8+CXHfddVntvWh6enqyupozkSbmjXz9KO9148/3+5988smsrq5/VerD42O9/PLLs9rzQr7OWMkll+S/Rj4ez9X4Z+Hb+txzz2V1NavlmRtf98vX1ip97p7p8d9Pfz6A7tDp3MpCyvTMtYW6LzjDAwAAao8JDwAAqD0mPAAAoPa6qg+P51g8r+G9bTyb4j1aqv1cPLsxODiY1Z4F8d40nmtZtWpVVvuaTp798N41vpaWv9+uXbuy+oEHHphyPP5ehw8fzupNmzZlta/r5fv16NGjWV3NC0kT+x953x3/HD3T4zzDs3fv3qweGhoav13qAeQ9hDyj43kjzxcBAOqJMzwAAKD2mPAAAIDaY8IDAABqr+MZnmZ9TbwHivey8SyI52jcmTNnxm97Hmjbtm1ZXcoL+Xv5WHx9KM+aeHbEczJr167N6je96U1Z7b11qvvK99vIyEhW33zzzVl96aWXZrX3rvGeQz726n6VJmanfKynTp1SM56z8UzQ/v37x29fdtll2X3em8k/R39v/xz9cwLQnbptvaj57EXDvpgezvAAAIDaY8IDAABqjwkPAACovXntw+PZE++p4v1fPFfj2ZJXX301q6vZD8+teA8ff+6FCxey2nvFON8Wz+T4trjly5dnta8L1t/fn9XVPj6+3zyXcssttzQd28GDB7N648aNWe29anxdMN9XnpMprUflPY48E1TNDJUyO/474tkqzwv5vmq21hsAXNStORVMjTM8AACg9pjwAACA2mPCAwAAam9eMzye7fA8hq/J5I/3DI9nSY4dOzZ++6qrrmr6Wt5Xx9/b12jyx5fWcPL387WzPHvi97/lLW/J6uraXb621fbt27P62muvzWrvAeS8j45nfjxz4/kj3xdeV9c4kyZuu/faqfYF8vyQr4nmn4tns/y9/XeIDA/QHbqt14xbKL1n5kN133TTfuEMDwAAqD0mPAAAoPaY8AAAgNqb1wyPazdH4/kLz3dU8xil53p2w/uzeL7Icy7r16/Pat8Wfz/vVePZksceeyyr3/a2t2V1NcPz7LPPZvft2rUrq31bfD/5tvi2+lh9W7wuZYAOHTrU9Pm+L6sZIc8feQ8i/5yr+0kq58DI8ACYC92aa1lMOMMDAABqjwkPAACoveKEJyK2RcSjEfGtiHg6Ij7Q+Pn6iHgoInY3/ttXei0AwNzimA1MrpUMz6uSfi2l9PWIWCvpaxHxkKR/KOmRlNK9EXGPpHskfbCdN/c8hecnfN0k7/fizz98+HBWV9ef8vWgqr1dJuM5Es96lPrw+BpO/nwfj2/r5z//+ay+/fbbs/r973//+G3P/5w4cSKrfVs9w+P71TM83svG7/fPwfv0+L5ymzZtymrfl9U+PaWxlfa790fysZbW/QIWgDk7Zs+1bu+9MxMzye0s5P3STf2Kimd4UkpDKaWvN26flvSMpEFJd0i6v/Gw+yW9d47GCABoEcdsYHJtfUsrIrZLeoOkr0jqTykNNe46LKl/iufcLenuGYwRADANMz1mr9CqyR4CLEgth5YjYo2kP5P0KymlU9X70th1gEmvBaSU7ksp3ZxSunlGIwUAtGw2jtlLtXyyhwALUktneCJiqcb+4vxxSunPGz8+EhEDKaWhiBiQ1HyBphZ43x3Pa5QyPJ7HuPzyy6d8rZ6enqz2bIevZVV6L699Xa/S+lPe6+bFF19sOr5qduXWW2/N7nvooYey+oYbbsjqL3/5y1nt2SfnuRjfl57RKfVT8n3r237y5MmsPnPmzPht368+Ns/0+Ofs63aV8kXAQtSpYza+Zy6zKv5aCznTM59a+ZZWSPqopGdSSr9Tueszku5s3L5T0oOzPzwAQDs4ZgOTa+UMz1sk/QNJT0XEk42f/aakeyV9MiLukrRP0vsnfzoAoIM4ZgOTKE54UkpflDRVv/3bZnc4AICZ4JgNTG5e19Lyvjuep/Bsh+dgfB2ljRs3ZnU1v+G5E+/14rXnTkq9aLyPjj/ea+ev59v2xS9+Maufeuqp8du+vtS+ffuy+tOf/nRWHzx4MKu9J5DnlXws3/nOd7Lae9043/YNGzY0fbyvf1V9P9/Pp0+fzuotW7Zktf+O+bbQhweYP2RRWsN+mh0kNgEAQO0x4QEAALXHhAcAANReV2V4PE/hWRHP1XgPFu+5Us2m+Hv5a3l2w1/b+7/09eXr7pWyIJ5P8iyJZ3huvPHGrH7ssceyuppz8dcaGhrKas/srFy5Mqu3b9+e1aVtKfUU8vuHh4ez2j8n/2w8u1Xd15deeml2n+eXBgcHs9o/R3fu3LmmYwGAVtArp/txhgcAANQeEx4AAFB7THgAAEDtzWuGx3Mtnp/w3ExpzaWtW7dm9bp168Zve0bGsxve38VzMf54Xw/Kn+/b4jkYH4/3k/Ftra4n5a/nj/X1otauXZvV27Ztazr2Ut7IH+/b4p/boUOHstr79ngfIM8YVd/Pe/j4mmOlfkieN/KMD314AMw18j7zgzM8AACg9pjwAACA2uuqr6WXvhpeuhyxYsWKrK5+9dwvy5w4cSKr+/v7s3p0dDSr/avWJX5ZyC8z7dixI6uXLVuW1f7Vcr8sVb2kVr105/dJEy/zXHXVVVn97LPPZnWz/TjZ6/n9vq1+6dE/N78k559V9ffCL4eVluzw1gbNLpcBQCe0ewmLS2CzgzM8AACg9pjwAACA2mPCAwAAam9eMzylpSI8X+HLOXjWw/MdZ8+eHb/tX5X22vNBpVxKKTvimR/fturYpIm5mZGRkaz2zM+aNWumfK3rrrsuq19++eWsPnz4cFb/0A/9UNP39q+Ve97I97vz+31fOv9cva7yz6H0lfpSboylJQBMRydzNWR6poczPAAAoPaY8AAAgNpjwgMAAGpvXjM8ngXx/IX3TPG8hfdY8cxPtf+L50Z8iYJSLsXr0lIRpeyI99nxDFFPT09Wb9++PauruZ2XXnopu2/nzp1Z7X1wjh49mtVHjhzJas/4eN7Jt9X3XUlp3/jrV/e9Z6P8d6CU6/L7/XcOALoNGZ3ZwdEeAADUHhMeAABQe0x4AABA7XU8w1PNa3h+YvXq1VM+djJnzpzJas+iVPMbvhaVZ2Q8/+OvXRqbb4v38RkcHGz6fB9f6fWrWRbvw+OZmuuvvz6rh4eHs9ozOp6d8tyLv75vq/fG8R5D/nqew3HVx/vn4s/1bJVneLwfUrN1uwAA9cEZHgAAUHtMeAAAQO0x4QEAALU3r314PC/hORXP1XjewrMnJ06cyOpqbmbdunXZfZ5D8WzH6dOns9ozNt4PxjM3fr+vA+a9ZjwH49vqr1dVyp14hmZgYKDp870nkO8bH6vzsXrtfYE8H9UsQ+QZHv8dKGWf/PH+O0aGBwDqiTM8AACg9pjwAACA2itOeCJiRUQ8FhF/GxFPR8S/afx8R0R8JSL2RMQnIqK99QUAALOOYzYwuVYyPBckvT2ldCYilkr6YkT8paRflfThlNIDEfEHku6S9PszGYxnRUrrV3n+wvMa69evH7+9Zs2aps/1tba8LuWHSuuAldaP8ud7xsf7zVTv94xOKWNTyql4vmnVqlVZfe7cuaz2sfu2+XgOHDjQ9P02bdo05dj8d6LUw6e0Tlep1xOwAHXsmA0sJMUzPGnMxaTo0safJOntkj7V+Pn9kt47FwMEALSOYzYwuZYyPBGxJCKelHRU0kOSXpA0mlK62FL3gKTBKZ57d0Q8HhGPz8J4AQAFs3XMfkUXJnsIsCC1NOFJKb2WUrpJ0lZJt0i6ptU3SCndl1K6OaV08/SGCABox2wds5dqefkJwALRVh+elNJoRDwq6c2SeiPiksa/GLZKOtjKa1QzE54lKfWD8byFryHlqtkTf23v2eOZnVOnTmW151T89Tyn4mP3zJBngDyb4pkjz7lU98XGjRtbfqw0cVs8k+Nj8W3z12uWL5Imbotnjrwvj++76vOruazJNOtXJE3MUvm6X0CdzMYxG6iLVr6ltSkiehu3V0p6p6RnJD0q6X2Nh90p6cE5GiMAoEUcs4HJtXKGZ0DS/RGxRGMTpE+mlD4bEd+S9EBE/DtJT0j66ByOEwDQGo7ZwCSKE56U0jckvWGSn+/V2LVhAECX4JgNTK7ja2lV8x+en/DsR6mXjT+/We0ZHV+TyXMjvnaWZ3BK/V084+Nj9xyN9yAqrd3l46ny/eCZHN8X/t6esSnllXwsfr/X/f39We3bNjw8POV4fD87z0aV+hn5e7OWFgDUE0tLAACA2mPCAwAAao8JDwAAqL2OZ3iqGQnPfng/GM/VeH8Zz6b09vZmdTUL4rkUXx/Ka89+nD59OqtL/WBKmR3n7+eP99fbv3//+G3fbz5W3y+lfJHXpX5JpdyL52o8n+TP95xNtWeSb6tnqTyf5L8jpccDAOqJMzwAAKD2mPAAAIDaY8IDAABqr+MZnirvgeJ5Cs92eObHczlbt27N6mqvHc9yeGbH80HeO6aamZGkLVu2ZLVnQ0q5Fs/JeM+h0rphe/bsGb+9c+fO7L7Dhw9n9cDAQFb7tvm+8M/Fx+I8b+TP9z4/nn8q9SQ6cuTI+G3vn+Tb4nkhX8fLt4W1tABgceAMDwAAqD0mPAAAoPaY8AAAgNqb1z48nmMprU/lGR7PnngOpvpepZyJj8Xf23sCtZvR8ffz/JGPz1/fcznVfjQbNmzI7nvxxRez2vva+LaV1sbysfjn5LXnaLz29/PxeJ+egwcPjt/2/bZ69eqs9hyYj62npyeryfAAwOLAGR4AAFB7THgAAEDtMeEBAAC1N699eEo5GM9ftJuDqeY12l0PqpQr8ceX1r7yrEhpbS1//L59+7K6mlXxTMyxY8ey2tef8uyT72fP8Pi2lDI/ntnx/JP3RHLN+gStW7cuu2/Tpk1Nx+L8vUuPBwDUA2d4AABA7THhAQAAtceEBwAA1N68ZnhcKdfiGR7P2bjq/b5WlmdwPKfiWQ/PlXi/F39+qXdN6X7P3QwNDWV1dU2p0dHR7L7Tp09n9fDwcFZ7psaVslP+OXkOxtfC6uvry2rft6W1u6prb3luyzM9vt/8tUrZKgBz53OHnpzvIWAR4wwPAACoPSY8AACg9pjwAACA2uuqDI9nOUr5Cs/luGq2ZXBwMLuv3RyJ5148K1JaF8yV1to6depUVp88eTKrq7kZ79Hja2cdOXIkq713jSuNvbR2luebfP0qzwD55+yfzZo1a8Zvl9ZA86yVj9XH5vsKADB3PMf1o1tu6th7c4YHAADUHhMeAABQe0x4AABA7XVVhqe0rlGpd47nNao5mA0bNmT3+dpYpT493v/FcyulHkGeLSlleDyz41mT6vg8o+OZmOPHj2e198nxfFIpw+MZHB9bs7WwpPbXUKs+3jM4nnXy93K+b3y/l8YGAJi+TmZ2HGd4AABA7bU84YmIJRHxRER8tlHviIivRMSeiPhERDT/yhQAoGM4ZgO5ds7wfEDSM5X6tyR9OKW0U9KIpLtmc2AAgBnhmA1UtJThiYitkn5M0r+X9KsxFrJ4u6SfaTzkfkn/WtLvz2QwnmvxbIlnTzzP4XmMKl9fyrMenkvxeuXKlU3vL+VenG+rb8uJEyeyull+6ezZs01f2zM8/l6l/JJncpz3zamufSVNzDP5+Jy/f3XdsOptaWKGp9Tzx7NXrKWFOurUMbtdnt9gbS10UqtneH5X0m9Iuvh/qg2SRlNKF/9vcUDS4CTPAwB03u+KYzaQKU54IuLHJR1NKX1tOm8QEXdHxOMR8fh0ng8AaN1sHrNf0YXyE4AFopVLWm+R9BMR8W5JKyT1SPqIpN6IuKTxL4atkg5O9uSU0n2S7pOkiOA7vwAwt2btmN0T6zlmozaKE56U0ockfUiSIuKtkn49pfSzEfGnkt4n6QFJd0p6sJU3rOYzPPfi2Q6vPdvh61k1y6ZU19WSJvblcZ5L8RxLdX0nqXnvGGlivsizJT72oaGhrG6We/H+Rf5Yz7l4bsVzLaVt8df3nkbes6j0eqV9Vc1u+edYyuD45+Y9g0p5ImChme1jNlAXM+nD80GNheH2aOz68EdnZ0gAgDnAMRuLWludllNKX5D0hcbtvZJumf0hAQBmA8ds4Hu6ammJ0uWJ0leM/dJO9avkw8PD2X2l5RBKl11c6bKPv75ftvGvzftyEf761ctE/rVy55fL/L388l3p9XzspX3nn2vpMpK/fnVbm7UemGws/pV43xd8LR0AFgeWlgAAALXHhAcAANQeEx4AAFB7XZXh8WyHZ3JKGR5XfXzpK/DNciOTvXcps+OPd/5+e/fuzWpfLsJzNr29veO3t2/f3vS1Pb/k73XDDTdktWd4Svuq3XYCrvS5V7e99Dn6/aVlLfhaOgAsDpzhAQAAtceEBwAA1B4THgAAUHtdleHxHilnzpzJ6lWrVmW1Zz08K1J9Pc+llJYzaDeTU8r4OH+//fv3Z7Vndi677LKsvvrqq8dvX3rppdl91XyPNDGzc+DAgay+8sors9qXiigtXTHTTE/p+dVcju8Xfy2/3+t2ewIBAOqBMzwAAKD2mPAAAIDaY8IDAABqr+MZHu+TUuUZnvPnz2f1hg0bstrzF74+VjUb0tPT0/S5pRyJZ0U8T1Ra46mdsUoTczXXXnttVle3x9eP6u/vz2rP5HiuxT8TH0tpXbHSvvL7PUdTWs+qWYbHx17qIeS5sFLWCgBQD5zhAQAAtceEBwAA1B4THgAAUHtd1Yfn3LlzWe3ZDs+ieH7D8xnVnIz3pnGl3jCeufGsSGntLd8Wv/+mm27Kas/heGao+no+Nh/L8uXLs9rzQJ6LaTfD47Vva7t9etrh7+1rZ/nvxOnTp5s+HwBQT5zhAQAAtceEBwAA1B4THgAAUHtdleG5cOFC0/tL6ySNjIxkdTXPUcroeKamlMkp5Vaa9Rua7PmDg4NZ7b11fLzVbT158mR2X19fX9Pacy6lTI2/t2+rr7Xl/ZScv14pM9RsbP7eK1asyOrR0dGsLvXh8c+NjA8A1ANneAAAQO0x4QEAALXHhAcAANTevGZ4SjkY53kN763jeY1qL5tS7sTzQJ7Z8ftLSutJlR7vtY+nmnvx7JKvOVbKE/nY2l1b6+zZs01r7wNU+tyb7Tt/bedrpg0PD2d1KV8EoHN+dMtNWf25Q0/OyziwOHCGBwAA1B4THgAAUHtMeAAAQO11VR+eUs7F14waGBjI6gMHDmT1+vXrx297/xXvReO1r5XlSutDeebGtdunx1XH53mkUp+dUq+ZUv7IMzeeqzl//nxWe0+hdt+/+n6nTp3K7vNslWd4vLeT7ysAwOLAGR4AAFB7THgAAEDttXRJKyJeknRa0muSXk0p3RwR6yV9QtJ2SS9Jen9KaWSq1wAAdAbHbGCidjI8b0spHa/U90h6JKV0b0Tc06g/WHqRan6jlN3wnilHjhzJ6ssvvzyrn3vuuayu5j28F4z38HGeF/J61apVWe2ZH8/wlPr6eCbo9OnTWb1y5cqsbpZ38v127ty5rF63bl1Wt5vZKeWVPMPjfN+V+vJUX8+3ZfXq1U3HUlq3C6ixWTlmAzPhvZbm00wuad0h6f7G7fslvXfGowEAzBWO2VjUWp3wJEn/NyK+FhF3N37Wn1Iaatw+LKl/sidGxN0R8XhEPD7DsQIAWjMrx+xXdGGyhwALUquXtH4wpXQwIi6V9FBEPFu9M6WUImLS71GnlO6TdJ8kTfUYAMCsmpVjdk+s55iN2mhpwpNSOtj479GI+LSkWyQdiYiBlNJQRAxIOtria7U8OO+d4zmZa665pulrV7MsnoEpZT08Q+O5GM/0+PpVpfWnSo4dO5bVK1asmLL2XIuvH+Xv7fvR63bWtpIm5qO8z473zvF95zkc75VTfb7/TmzevDmrfdv9tUq9noA6mM1jNlAXxUtaEbE6ItZevC3pRyR9U9JnJN3ZeNidkh6cq0ECAFrDMRuYXCtnePolfbrxr/ZLJP1JSumvIuKrkj4ZEXdJ2ifp/XM3TABAizhmA5MoTnhSSnsl3TjJz09Ium0uBgUAmB6O2cDkumotLXfy5Mms9v4tnsfw+6s8J+K5FO8dc/z48azu6+tr+t5el9a3Kq2l5Rmg0dHRrF67du34bc8Xec7F8z+eofG1rkq9a7z2PFR1bNLEsY+M5L3OfHz++tUMj2/r61//+qx++eWXs9p/h8jwAMDixNISAACg9pjwAACA2mPCAwAAam9eMzyeY/FcjWdRfP0p77kyMDCQ1UePfq/NhGdqzp4927T23jb9/XlT0mZ5IWliVsS3rbSmk7++Z1equRhfG6unpyerfb/5WHzflHoS+f3e48j78nh+ybfF39/r6mfhz92yZUtWP/PMM1ntPYBK2u2XBGD2VNdd+tyhJ+dtHJiZblo/q4ozPAAAoPaY8AAAgNpjwgMAAGqvq/vweL8Yz8UcOnQoq6+66qqsfvHFF8dve18dz5X4+lGeQ7lwIV812HvNlPru+Ot77xrn7++q4/EeQ97Xxt/Ls1OlDI/30fHHb9q0qen93uPI+eOb9RXyvJBnrZzfT0YHABYnzvAAAIDaY8IDAABqjwkPAACovY5neKr5kVKewjM73g/Gn//GN74xq6vZFV+/ybMg3stm2bJlWe05k9JaWiX+eM/VeO3jqWZ8vF+R51a8D09pTbLS2lmesfGsleedfDy+bf58357q575z587svueffz6rPSvlY3FkeoDu5L1c6MuDmeIMDwAAqD0mPAAAoPaY8AAAgNrreIZnJpkJz+H09fVltWdFNm7cOH775MmT2X1r1qzJas+5lDI6nhXxurSd3hun3V451RyN9xjy9/aeQM57/pTySL6tnvHx+33sPj7PZnnfn2ofH++19MQTT2S1f86lNc0AAIsDZ3gAAEDtMeEBAAC1x4QHAADU3oLK8Jw9ezarPXeze/furL7++uvHbz/88MPZfRs2bMjq0ppMnvnxnIr3kvHt9JyL3+99gXzbfNuruRbPvPhzfez+Wp7x8bF6nsh725QyPb6tvq+Gh4ez2nM41bXCfNuc7wsyOwAwt7xnUrfiDA8AAKg9JjwAAKD2On5Jayb8683+dWZfkuC6664bv71kyZLsPv+Ke2kpB3++X7YpXdLy1/exb926NaubfQ3d36+0NIMvJVG9HCbll4yk8tfSS0tLlL6i79vm+9Ivcd14443jt1966aWm7+XbBqAeWGqieyyUS1iOMzwAAKD2mPAAAIDaY8IDAABqr6szPKWvFJ84cSKr+/v7s/rw4cPjt6+88srsvueffz6re3t7s9ozN6WlJTzH4s93p06davp6nmvxr4JXsyr+Ve21a9dmtS9b0e7XyJ1ncEqZnNLSE5458n1d/ez+5m/+JruvtJQEgHoi04N2cYYHAADUHhMeAABQey1NeCKiNyI+FRHPRsQzEfHmiFgfEQ9FxO7Gf/vKrwQAmGscs4GJWs3wfETSX6WU3hcRyyStkvSbkh5JKd0bEfdIukfSB+donJPyHMzmzZuzeu/eveO33/zmN2f3Pfvss1ntWRBfbsF7zzjPsXiuxrMlpeUWSss5VPv4+FiXL1/e9L39tX3snrHxDJD3JCrtG++N4+PxLNb27duz2nsWVbGUBDCprjxmY2FaqH13XPEMT0Ssk/TDkj4qSSml76SURiXdIen+xsPul/TeuRkiAKBVHLOBybVySWuHpGOS/ltEPBERfxgRqyX1p5SGGo85LKl/sidHxN0R8XhEPD47QwYANDFrx+xXdGGyhwALUisTnkskvVHS76eU3iDprMZOhY5LY9cRJr2WkFK6L6V0c0rp5pkOFgBQNGvH7KVaPtlDgAWplQzPAUkHUkpfadSf0thfniMRMZBSGoqIAUlH52qQF3k+o1muRZJWrFgxfvvcuXPZfTt37szqF198Mau9l43nhTzH4jkYz9G0m9Hxtby8l011W32tLH9saWx+v/fFqe5HSVq5cmXTx5e2vZS7ecMb3pDVTz311JSvVcoPAYtQ1xyzgW5SPMOTUjosaX9EXN340W2SviXpM5LubPzsTkkPzskIAQAt45gNTK7Vb2n9E0l/3Ej775X0cxqbLH0yIu6StE/S++dmiACANnHMBkxLE56U0pOSJsvg3DarowEAzBjHbGCirl5Lq8T7uRw/fjyrd+zYMX67mgORJvbl2bdvX1aPjIw0fW/P8HhuxnMvZ8+ezWrvbePZFL/f+/pU7/cMjudavK+OZ3BKz/f97Nu2f//+rF6zZk1We8bH++5cccUVTcdbHY8/1/e7oy8PsDiwthZKWFoCAADUHhMeAABQe0x4AABA7S3oDI/nMzwnU83FeC7E8z67du3K6m984xtZ7etVlXjOZXh4OKs3btyY1T4+r70vz4YNG8ZvHzlyJLuvWT8iaWL+yN/L+ev5WDzz45mdY8eOZbVniN70pjdl9dNPPz3lWLyf0kwzOt4PyZEBAhYmMj3TV5e1sxxneAAAQO0x4QEAALXHhAcAANTegs7wOO/JcvTo95aK2bp1a3bf7t27s9pzJL621smTJ7Pacy++fpTnVryvT19fX9PX89r78qxevXrKx3rmZt26dVldWsfL++74OmLeE8izU/740lpZ/nh/vWr+yfsVuVLmppTZAVBPZHq+p64ZnRLO8AAAgNpjwgMAAGqPCQ8AAKi9WmV4PL9Rzd143xvPoXgvm1tvvTWrP//5z2e150w8w+OZn1JuZtWqVVndzhpRvt3+2t43x3Mw3jfH19byTJA/3u/38ezcuTOrBwcHs/rxxx/Pat/20dHR8dueL5op/1zouwMsDosp07NYMzuOMzwAAKD2mPAAAIDaY8IDAABqr1YZHlftT+N9cbZt25bVL730UlZ7rxhfa+v555/Pas/srFmzJqs9R+MZIF9fynl2pZqj8ef62lbOMzcnTpzIas8A+bpj58+fz2pfm2vLli1ZfeONN2b1nj17stq3rZrZ8fHMdcaGDA+wONUp00NmZ3Kc4QEAALXHhAcAANQeEx4AAFB7tc7wVPMYnrHZvHlzVnvvF19r6+qrr85qz508++yzWe3vV+qz4zkYz/z4WlrVnI7nhVw7a1VN9vjSul7eV+eGG27I6uqaZtLEPJX3wvHxzHbvnSoyOwA6bbbzQmR2WsMZHgAAUHtMeAAAQO0x4QEAALVX6wxPNRvimRlfO8t7x3iOZO/evVm9Y8eOrPb1qfbt25fVnovxx/v6Vb7W14oVK7K6mgnyx3rGxvvseJ8bzxt5Zsb7/PT09GS19yjy1/N953klz/h4H6C5zNmQ4QEwmVIupt3cTbPXazfTQ2ZnejjDAwAAao8JDwAAqD0mPAAAoPZqneFpls/w9aTOnTuX1Z6ZGRoaymrP4PT392e199F5+eWXs9pzKp6r8d40a9euzepqzsaf62tpee19eHysGzZsyGrftoGBgaweGRnJas8vecbI97WPn747ALrdXOZoyOjMDc7wAACA2itOeCLi6oh4svLnVET8SkSsj4iHImJ34799nRgwAGBqHLOByRUnPCml51JKN6WUbpL0JknnJH1a0j2SHkkpXSnpkUYNAJhHHLOBybWb4blN0gsppX0RcYektzZ+fr+kL0j64OwNbW553xvvy3PZZZdltedKSjkYf/7GjRuz2jM9hw8fzmrPuXhfoGrtuRTPzHjtGR1fV6yvL/+H3/r167Pa808vvvhiVnv+yMfn+9o/C3989fXI4ABtqc0xG5ipdjM8PyXp443b/Smli0new5L6J38KAGCecMwGGlqe8ETEMkk/IelP/b409s/uSf/pHRF3R8TjEfH4tEcJAGjLbByzX9GFyR4CLEjtnOG5XdLXU0oXr0cciYgBSWr89+hkT0op3ZdSujmldPPMhgoAaMOMj9lLtbxDQwXmXjsZnp/W906NStJnJN0p6d7Gfx+cxXHNOc+CeGbGMzXei8YfX+p1s2nTpqy++uqrs9ozPseOHctqz/BU1wbztbPWrVuX1Z7J8bF4z6HSumA+FueZId+X58+fz+pmmZ3J7gfQklods4GZaukMT0SslvROSX9e+fG9kt4ZEbslvaNRAwDmGcdsYKKWzvCklM5K2mA/O6GxbwAAALoIx2xgIjotAwCA2qv1Wlrt8D47J0+ezGrPpfT29ma1516OHs3zgL52ludovNeNv/6ZM2cmDrph9erVWb1kyZKs9kyM5418nbDjx483fe81a9ZktWeIfNu9b4/va8/okNkBAMw2zvAAAIDaY8IDAABqjwkPAACovUWb4SnlRKp9biTpxIkTWe3rP3kmx3lu5sCBA1ntvW080+O9dap9gF599dXsPu8B5Bkcz+j4893y5XnzsVJeyd/P96UjswMAmGuc4QEAALXHhAcAANQeEx4AAFB7izbDU+K5Es+hlHrL+NpY3rvG1+LyDI/nZHw9Ku990+y5pT433mPIMzueXxodHc1q3xYyOQCAbsMZHgAAUHtMeAAAQO1xSatFfpnGv8rtl7j8a+t9fX1Z7V8z90tUflnKL5lV62aXt6SJS0+48+fPZ/XBgwez+tSpU1nt2166hMUlLgDAfOMMDwAAqD0mPAAAoPaY8AAAgNojwzNLPGPjuRjP5Hgupre3N6tXrlyZ1StWrGh5LKWlJkZGRtoaa7tLQ0RES+MEAKBTOMMDAABqjwkPAACoPSY8AACg9sjwTFMpt1Lq2+O5mm9/+9tZvXTp0qxuluEpvZdncrxHUGnpidL7tXs/AACdxhkeAABQe0x4AABA7THhAQAAtUeGZ5a0m1vxvj3e68ZzNt4rpx3tjo0MDgCgbjjDAwAAao8JDwAAqD0mPAAAoPbI8MyTdnvZkKsBAGD6OMMDAABqjwkPAACovZYmPBHxzyLi6Yj4ZkR8PCJWRMSOiPhKROyJiE9ExLK5HiwAoIxjNjBRccITEYOS/qmkm1NK10laIumnJP2WpA+nlHZKGpF011wOFABQxjEbmFyrl7QukbQyIi6RtErSkKS3S/pU4/77Jb131kcHAJgOjtmAKU54UkoHJf22pJc19pfmpKSvSRpNKV1clvuApMHJnh8Rd0fE4xHx+OwMGQAwldk8Zr+iC50YMtARrVzS6pN0h6QdkrZIWi3pXa2+QUrpvpTSzSmlm6c9SgBAS2bzmL1Uy+dolEDntXJJ6x2SXkwpHUspvSLpzyW9RVJv43SpJG2VdHCOxggAaB3HbGASrUx4XpZ0a0SsioiQdJukb0l6VNL7Go+5U9KDczNEAEAbOGYDk2glw/MVjQXdvi7pqcZz7pP0QUm/GhF7JG2Q9NE5HCcAoAUcs4HJRSeXLIgI1kfAQvM18mdYrHpiffr+uG2+hwG07OH0qSmP2XRaBgAAtceEBwAA1B4THgAAUHtMeAAAQO11OrR8TNI+SRslHe/YG7eHsU1fN49vumO7PKW0abYHAywEHLNnRTePr45jm/KY3dEJz/ibRjzerd98YWzT183j6+axAd2um//+dPPYpO4e32IbG5e0AABA7THhAQAAtTdfE5775ul9W8HYpq+bx9fNYwO6XTf//enmsUndPb5FNbZ5yfAAAAB0Epe0AABA7XV0whMR74qI5yJiT0Tc08n3nmI8H4uIoxHxzcrP1kfEQxGxu/Hfvnka27aIeDQivhURT0fEB7plfBGxIiIei4i/bYzt3zR+viMivtL4fD8REcs6PbbKGJdExBMR8dluGxuwkHTTcZtj9rTHxjFbHZzwRMQSSf9Z0u2Svk/ST0fE93Xq/afwR5LeZT+7R9IjKaUrJT3SqOfDq5J+LaX0fZJulfTLjf3VDeO7IOntKaUbJd0k6V0Rcauk35L04ZTSTkkjku6ah7Fd9AFJz1TqbhobsCB04XH7j8Qxezo4ZquzZ3hukbQnpbQ3pfQdSQ9IuqOD7z9BSumvJQ3bj++QdH/j9v2S3tvJMV2UUhpKKX29cfu0xn4RBrthfGnMmUa5tPEnSXq7pE/N59gkKSK2SvoxSX/YqKNbxgYsMF113OaYPe2xccxWZyc8g5L2V+oDjZ91m/6U0lDj9mFJ/fM5GEmKiO2S3iDpK+qS8TVOPz4p6aikhyS9IGk0pfRq4yHz+fn+rqTfkPTdRr1B3TM2YCFZCMftrjgmVnHMbtvvqgPHbELLTaSxr7DN69fYImKNpD+T9CsppVPV++ZzfCml11JKN0naqrF/BV4zH+NwEfHjko6mlL4232MB0Fkcs6fGMVu6ZK7foOKgpG2VemvjZ93mSEQMpJSGImJAY7PheRERSzX2F+ePU0p/3m3jk6SU0mhEPCrpzZJ6I+KSxqx8vj7ft0j6iYh4t6QVknokfaRLxgYsNAvhuN01x0SO2dPSsWN2J8/wfFXSlY3k9TJJPyXpMx18/1Z9RtKdjdt3SnpwPgbRuIb5UUnPpJR+p3LXvI8vIjZFRG/j9kpJ79TY9epHJb1vPseWUvpQSmlrSmm7xn7HPp9S+tluGBuwAC2E4/a8HxMljtnT1dFjdkqpY38kvVvS8xq7dvgvOvneU4zn45KGJL2isWuEd2ns2uEjknZLeljS+nka2w9q7NTnNyQ92fjz7m4Yn6QbJD3RGNs3Jf2rxs9fL+kxSXsk/amk5fP8+b5V0me7cWz84c9C+dNNx22O2dMeG8fslOi0DAAA6o/QMgAAqD0mPAAAoPaY8AAAgNpjwgMAAGqPCQ8AAKg9JjwAAKD2mPAAAIDaY8IDAABq7/8D+KfaJlB7KGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 32]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 32], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 32])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 Load and cache transformed data:  [==============================]\n",
      "9/9 Load and cache transformed data:  [==============================]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=0)\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "model_path = os.path.join(root_dir, \"best_metric_model_ixi_tiny.pth\")\n",
    "if (os.path.exists(model_path)):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f\"Loaded model from file '{model_path}'\")\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 11 and 12 in dimension 2 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-73b68b1d136e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         )\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\nets\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\monai\\pyenv\\lib\\site-packages\\monai\\networks\\layers\\simplelayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 11 and 12 in dimension 2 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (-1, -1, -1)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                value = compute_meandice(\n",
    "                    y_pred=val_outputs,\n",
    "                    y=val_labels,\n",
    "                    include_background=False,\n",
    "                    to_onehot_y=True,\n",
    "                    mutually_exclusive=True,\n",
    "                )\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f}  at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best model output with the input image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        roi_size = (-1, -1, -1)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "        )\n",
    "        # plot the slice [:, :, 32]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 32], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 32])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.argmax(val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
